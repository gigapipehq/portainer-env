networks:
  monitoring-net:
    driver: bridge

services:
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    hostname: clickhouse-server
    restart: unless-stopped
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - "${CLICKHOUSE_DATA_PATH}:/var/lib/clickhouse"
    networks:
      - monitoring-net
    environment:
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      S3_HOST: ${S3_HOST:-}
      S3_BUCKET: ${S3_BUCKET:-}
      S3_PREFIX: ${S3_PREFIX:-}
      S3_KEY: ${S3_KEY:-}
      S3_SECRET: ${S3_SECRET:-}
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -e
        mkdir -p "/etc/clickhouse-server/config.d"
        if [ -n "$$S3_HOST" ]; then
            echo "S3 credentials found. Generating S3 storage configuration."
            cat > "/etc/clickhouse-server/config.d/storage.xml" <<EOF
        <clickhouse>
          <storage_configuration>
            <disks>
                <default><keep_free_space_bytes>21474836480</keep_free_space_bytes></default>
                <s3_storage>
                    <type>s3</type>
                    <endpoint>$${S3_HOST}/$${S3_BUCKET}/$${S3_PREFIX:-}</endpoint>
                    <access_key_id>$${S3_KEY}</access_key_id>
                    <secret_access_key>$${S3_SECRET}</secret_access_key>
                    <metadata_path>/var/lib/clickhouse/s3_metadata/</metadata_path>
                    <cache_enabled>true</cache_enabled>
                    <data_cache_enabled>true</data_cache_enabled>
                    <cache_path>/var/lib/clickhouse/s3_cache/</cache_path>
                    <max_cache_size>2Gi</max_cache_size>
                    <thread_pool_size>100</thread_pool_size>
                </s3_storage>
            </disks>
            <policies>
                <tiered>
                    <volumes>
                        <default><disk>default</disk><volume_priority>1</volume_priority></default>
                        <s3><disk>s3_storage</disk><prefer_not_to_merge>false</prefer_not_to_merge><perform_ttl_move_on_insert>false</perform_ttl_move_on_insert><volume_priority>2</volume_priority></s3>
                    </volumes>
                    <move_factor>0.05</move_factor>
                </tiered>
            </policies>
          </storage_configuration>
        </clickhouse>
        EOF
            echo "Configuration file '/etc/clickhouse-server/config.d/storage.xml' created."
        else
            echo "S3 credentials not found or incomplete. Skipping S3 storage configuration."
            rm -f "/etc/clickhouse-server/config.d/storage.xml"
        fi
        exec /entrypoint.sh
    healthcheck:
      test:
        ["CMD", "wget", "--spider", "-q", "http://clickhouse-server:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  gigapipe-init:
    image: ghcr.io/metrico/gigapipe:v4.0.20
    container_name: gigapipe-init
    restart: "no"
    networks:
      - monitoring-net
    environment:
      CLICKHOUSE_SERVER: "clickhouse-server"
      CLICKHOUSE_AUTH: "${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}"
      CLICKHOUSE_DB: "${CLICKHOUSE_DB}"
      PORT: "9080"
      MODE: "init_only"
    depends_on:
      clickhouse:
        condition: service_healthy

  clickhouse-ttl-init:
    image: clickhouse/clickhouse-client:latest
    container_name: clickhouse-ttl-init
    restart: "no"
    networks:
      - monitoring-net
    environment:
      CLICKHOUSE_SERVER: "clickhouse-server"
      CLICKHOUSE_DB: "${CLICKHOUSE_DB}"
      CLICKHOUSE_USER: "${CLICKHOUSE_USER}"
      CLICKHOUSE_PASSWORD: "${CLICKHOUSE_PASSWORD}"
      CLICKHOUSE_S3_TTL_DAYS: "${CLICKHOUSE_S3_TTL_DAYS}"
      CLICKHOUSE_TTL_DAYS: "${CLICKHOUSE_TTL_DAYS}"
      S3_HOST: "${S3_HOST}"
    depends_on:
      gigapipe-init:
        condition: service_completed_successfully
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -e
        echo "Starting TTL update process..."

        if [ -n "$$S3_HOST" ] && [ "$${CLICKHOUSE_S3_TTL_DAYS:-0}" -gt 0 ]; then
            echo "S3 storage is active and TTL is set to $$CLICKHOUSE_S3_TTL_DAYS days. Applying TTL MOVE policies..."
            
            TABLES_DATE="profiles_series profiles_series_gin profiles_series_keys tempo_traces_attrs_gin tempo_traces_kv time_series time_series_gin"
            TABLES_NS="metrics_15s profiles samples_v3 tempo_traces"
            TABLES_10M="patterns"

            for table in $$TABLES_DATE; do
                echo "Updating $$table..."
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" -q "ALTER TABLE $$table MODIFY SETTING storage_policy = 'tiered';"
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" --materialize_ttl_after_modify=0 -q "ALTER TABLE $$table MODIFY TTL date + toIntervalDay($$CLICKHOUSE_S3_TTL_DAYS) TO VOLUME 's3', date + toIntervalDay($$CLICKHOUSE_TTL_DAYS) DELETE;"
            done
            
            for table in $$TABLES_NS; do
                echo "Updating $$table..."
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" -q "ALTER TABLE $$table MODIFY SETTING storage_policy = 'tiered';"
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" --materialize_ttl_after_modify=0 -q "ALTER TABLE $$table MODIFY TTL toDateTime(intDiv(timestamp_ns,1000000000)) + toIntervalDay($$CLICKHOUSE_S3_TTL_DAYS) TO VOLUME 's3', toDateTime(intDiv(timestamp_ns,1000000000)) + toIntervalDay($$CLICKHOUSE_TTL_DAYS) DELETE;"
            done

            for table in $$TABLES_10M; do
                echo "Updating $$table..."
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" -q "ALTER TABLE $$table MODIFY SETTING storage_policy = 'tiered';"
                clickhouse-client --host "$$CLICKHOUSE_SERVER" --user "$$CLICKHOUSE_USER" --password "$$CLICKHOUSE_PASSWORD" --database "$$CLICKHOUSE_DB" --materialize_ttl_after_modify=0 -q "ALTER TABLE $$table MODIFY TTL toDateTime(timestamp_10m * 600) + toIntervalDay($$CLICKHOUSE_S3_TTL_DAYS) TO VOLUME 's3', toDateTime(timestamp_10m * 600) + toIntervalDay($$CLICKHOUSE_TTL_DAYS) DELETE;"
            done
            
            echo "TTL MOVE policies applied successfully."
        else
            echo "S3 storage not configured or CLICKHOUSE_S3_TTL_DAYS is not greater than 0. Skipping TTL update."
        fi

        echo "TTL update process finished."

  gigapipe-writer:
    image: ghcr.io/metrico/gigapipe:v4.0.21
    container_name: gigapipe-writer
    hostname: gigapipe-writer
    restart: unless-stopped
    ports:
      - "${WRITER_PORT}:9080"
    networks:
      - monitoring-net
    environment:
      CLICKHOUSE_SERVER: "clickhouse-server"
      CLICKHOUSE_AUTH: "${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}"
      CLICKHOUSE_DB: "${CLICKHOUSE_DB}"
      PORT: "9080"
      MODE: "writer"
    depends_on:
      clickhouse-ttl-init:
        condition: service_completed_successfully

  gigapipe-reader:
    image: ghcr.io/metrico/gigapipe:v4.0.21
    container_name: gigapipe-reader
    hostname: gigapipe-reader
    restart: unless-stopped
    ports:
      - "${READER_PORT}:9080"
    networks:
      - monitoring-net
    environment:
      CLICKHOUSE_SERVER: "clickhouse-server"
      CLICKHOUSE_AUTH: "${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}"
      CLICKHOUSE_DB: "${CLICKHOUSE_DB}"
      PORT: "9080"
      MODE: "reader"
    depends_on:
      clickhouse-ttl-init:
        condition: service_completed_successfully
